# PRUEBA-T√âCNICA

Resoluci√≥n de la prueba t√©cnica para Data Engineer. Incluye ejercicios de Python orientado a objetos y DAGs en Apache Airflow

## üìÇ Estructura b√°sica del repositorio  

```
de-tech-challenge/
‚îú‚îÄ README.md
‚îú‚îÄ python/
‚îÇ  ‚îî‚îÄ personas.py
‚îî‚îÄ dags/
   ‚îú‚îÄ test_dag.py


---

## 1) Ejercicio Python ‚Äì POO (`python/personas.py`)  

**Qu√© se demuestra**  
- Herencia (`Trabajador` hereda de `Persona`).  
- Uso correcto de `__init__`, con valores por defecto (`departamento="Data"`, `puesto="Analyst"`).  
- Sobrescritura de m√©todo (`presentation`), manteniendo la funcionalidad original con `super()`.  
- Creaci√≥n de instancias desde una **lista** (`*args`) y desde un **diccionario** (`**kwargs`).  
- Explicaci√≥n de la diferencia entre `self.nombre` (atributo del objeto) y `nombre` (variable local).  

**Ejecutar el script**  

```bash
cd python
python personas.py
```

Se imprimir√°n las presentaciones de las distintas instancias.  

---

## 2) Ejercicio Airflow (`airflow/dags/test_dag.py`)  

**Qu√© se demuestra**  
- DAG en Airflow 2.x con ejecuci√≥n diaria a las **03:00 UTC** (`0 3 * * *`).  
- Flujo de dependencias: `start` ‚Üí lista de `task_n` ‚Üí `timediff` ‚Üí `end`.  
- Cada tarea **par** depende de **todas las impares** (fan-in).  
- Operador personalizado `TimeDiffOperator` que:  
  - Recibe una fecha (`str` o `datetime`).  
  - Calcula y muestra en logs la diferencia con la fecha actual.  
- Comentario que explica la diferencia entre **Connection** y **Hook** en Airflow.  

---

## üöÄ Ejecuci√≥n r√°pida con Docker (recomendado)  

**Requisitos**: Docker y Docker Compose.  

```bash
cd airflow
docker compose up -d

# Inicializaci√≥n (ejecutar una sola vez)
docker compose exec airflow-webserver airflow db init
docker compose exec airflow-webserver airflow users create   --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com

# Reiniciar servicios
docker compose restart
```

Abrir Airflow en **http://localhost:8080** con user/pass `admin`/`admin`.  
Habilitar el DAG `test` y lanzarlo.  

---

## üñ•Ô∏è Ejecuci√≥n en local (sin Docker)  

**Requisitos**: Python 3.10+  

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt

# Configuraci√≥n m√≠nima
export AIRFLOW_HOME="$(pwd)/.airflow_home"
airflow db init
airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com

# Arrancar Airflow
airflow webserver --port 8080 &
airflow scheduler
```

Abrir http://localhost:8080, habilitar el DAG `test` y ejecutarlo.  

---

## ‚úÖ Sugerencia de commits  

- `python: a√±adir clases Persona/Trabajador`  
- `python: sobrescribir presentation y a√±adir valores por defecto`  
- `python: instancias desde lista y diccionario`  
- `airflow: DAG de prueba con dependencias`  
- `airflow: operador personalizado TimeDiff`  
- `docs: a√±adir README y quickstart`  

---

## üìå FAQ ‚Äì Puntos de razonamiento esperados  

- **`self.nombre` vs `nombre`**:  
  - `self.nombre` es un atributo ligado al estado de la instancia.  
  - `nombre` es una variable local al √°mbito actual.  

- **Airflow Connection vs Hook**:  
  - Una *Connection* es la configuraci√≥n (host, user, password, etc.) guardada en el metastore.  
  - Un *Hook* es una clase que usa esa *Connection* para abrir la conexi√≥n real y ejecutar operaciones (ej. `S3Hook`, `PostgresHook`).  

- **Dependencia pares/impares**: demuestra l√≥gica para generar dependencias din√°micas en DAGs.  

- **Custom Operator**: demuestra herencia desde `BaseOperator`, manejo de argumentos, logging y return.  
